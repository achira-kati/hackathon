{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "143929e6-005d-45da-93c7-886853d1916c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install transformers wandb\n",
    "# !pip install gdown pandas scikit-learn evaluate emoji pythainlp==2.2.4 sefr_cut tinydb seqeval sentencepiece pydantic jsonlines\n",
    "# !pip install --no-deps thai2transformers==0.1.2\n",
    "# !pip install transformers[torch]\n",
    "# !pip install jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e3cc656-5dc1-428b-8c9c-a0c6cd279862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gdown\n",
    "\n",
    "# url = \"https://drive.google.com/file/d/19xt3kgVvSXcbXQdjsT3wqiz6a-UdAbht/view?usp=sharing\"\n",
    "# output = \"nithan.zip\"\n",
    "# gdown.download(url=url, output=output, fuzzy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33629783-f77c-4daa-859a-af0f3c469316",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0ddfe7d-96d2-479f-95d1-f995261ae15d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>images/0/3.jpg</td>\n",
       "      <td>ของ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>images/0/6.jpg</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>images/0/5.jpg</td>\n",
       "      <td>ได้</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>images/0/0.jpg</td>\n",
       "      <td>ฉัน</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>images/0/7.jpg</td>\n",
       "      <td>ของ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>images/4/49990.jpg</td>\n",
       "      <td>บัดนี้</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>images/4/49997.jpg</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>images/4/49996.jpg</td>\n",
       "      <td>เดินทาง</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>images/4/49998.jpg</td>\n",
       "      <td>ก็</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>images/4/49999.jpg</td>\n",
       "      <td>ถึง</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                file_name     text\n",
       "0          images/0/3.jpg      ของ\n",
       "1          images/0/6.jpg        _\n",
       "2          images/0/5.jpg      ได้\n",
       "3          images/0/0.jpg      ฉัน\n",
       "4          images/0/7.jpg      ของ\n",
       "...                   ...      ...\n",
       "49995  images/4/49990.jpg   บัดนี้\n",
       "49996  images/4/49997.jpg        _\n",
       "49997  images/4/49996.jpg  เดินทาง\n",
       "49998  images/4/49998.jpg       ก็\n",
       "49999  images/4/49999.jpg      ถึง\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('single_result/gt.txt', header=None, sep='\\t')\n",
    "df.columns = ['file_name', 'text']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c1d3401-31bd-4231-82bc-5617eadf67ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from thai2transformers.preprocess import process_transformers\n",
    "# from transformers import AutoTokenizer\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"airesearch/wangchanberta-base-att-spm-uncased\", model_max_length=416)\n",
    "\n",
    "# def find_length(text):\n",
    "#     text = process_transformers(text)\n",
    "#     tokens = tokenizer(text)\n",
    "#     return len(tokens['input_ids'])\n",
    "\n",
    "# df['tokens_length'] = df['text'].apply(find_length)\n",
    "\n",
    "# max_length = df['tokens_length'].max()\n",
    "# min_length = df['tokens_length'].min()\n",
    "# avg_length = df['tokens_length'].mean()\n",
    "# length_95 = df['tokens_length'].quantile(0.95)\n",
    "# length_99 = df['tokens_length'].quantile(0.99)\n",
    "\n",
    "# print(f\"Maximum tokens length: {max_length}\")\n",
    "# print(f\"Minimum tokens length: {min_length}\")\n",
    "# print(f\"Average tokens length: {avg_length}\")\n",
    "# print(f\"95% of the texts have length less than or equal to: {length_95}\")\n",
    "# print(f\"99% of the texts have length less than or equal to: {length_99}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d84e851-0bbf-41e1-a24c-854c001c7fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2)\n",
    "# we reset the indices to start from zero\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "208e8d3f-16ea-4938-88c0-93e0d3327e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from thai2transformers.preprocess import process_transformers\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, root_dir, df, processor, max_target_length=20):\n",
    "        self.root_dir = root_dir\n",
    "        self.df = df\n",
    "        self.processor = processor\n",
    "        self.max_target_length = max_target_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # get file name + text \n",
    "        file_name = self.df['file_name'][idx]\n",
    "        text = self.df['text'][idx]\n",
    "        # prepare image (i.e. resize + normalize)\n",
    "        if text == '_':\n",
    "            image = Image.open(self.root_dir + file_name).convert(\"RGB\")\n",
    "            size = image.size[0]\n",
    "            image = image.resize((size*2, size))\n",
    "        else:\n",
    "            image = Image.open(self.root_dir + file_name).convert(\"RGB\")\n",
    "\n",
    "        pixel_values = self.processor(image, return_tensors=\"pt\").pixel_values\n",
    "        # add labels (input_ids) by encoding the text\n",
    "        text = process_transformers(text)\n",
    "        labels = self.processor.tokenizer(text, \n",
    "                                          padding=\"max_length\",\n",
    "                                          truncation=True,\n",
    "                                          max_length=self.max_target_length).input_ids\n",
    "        # important: make sure that PAD tokens are ignored by the loss function\n",
    "        labels = [label if label != self.processor.tokenizer.pad_token_id else -100 for label in labels]\n",
    "    \n",
    "        encoding = {\"pixel_values\": pixel_values.squeeze(), \"labels\": torch.tensor(labels)}\n",
    "        return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "111383b7-7f9d-4972-8ea7-2344f6279ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import VisionEncoderDecoderModel, AutoTokenizer, ViTImageProcessor, TrOCRProcessor\n",
    "\n",
    "# image_processor = TrOCRProcessor.from_pretrained('microsoft/trocr-base-handwritten').image_processor\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"airesearch/wangchanberta-base-att-spm-uncased\", model_max_length=416)\n",
    "# processor = TrOCRProcessor(image_processor=image_processor, tokenizer=tokenizer)\n",
    "processor = TrOCRProcessor.from_pretrained('kkatiz/thai-trocr-thaigov-v2')\n",
    "\n",
    "train_dataset = MyDataset(root_dir='single_result/',\n",
    "                           df=train_df,\n",
    "                           processor=processor)\n",
    "eval_dataset = MyDataset(root_dir='single_result/',\n",
    "                           df=test_df,\n",
    "                           processor=processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ef18ed4-74b6-4a75-bb18-8e44b9587b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 40000\n",
      "Number of validation examples: 10000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training examples:\", len(train_dataset))\n",
    "print(\"Number of validation examples:\", len(eval_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "873ee628-8d68-4b90-8c0e-4661cc073e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixel_values torch.Size([3, 384, 384])\n",
      "labels torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "encoding = train_dataset[0]\n",
    "for k,v in encoding.items():\n",
    "  print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ea31c07-fdef-4232-8b37-eaaccad20169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm.auto import tqdm\n",
    "\n",
    "# for i in tqdm(range(len(train_dataset))):\n",
    "#     encoding = train_dataset[i]\n",
    "#     if len(encoding['labels']) != train_dataset.max_target_length:\n",
    "#         print(f\"Label at index {i} has length {len(encoding['labels'])}, which is not equal to max_target_length.\")\n",
    "#         break\n",
    "#     if encoding['pixel_values'].size(0) != 3:\n",
    "#         print(f\"Label at index {i} has pixel_values {encoding['pixel_values'].shape}\")\n",
    "#         break\n",
    "\n",
    "#     labels = encoding['labels']\n",
    "#     labels[labels == -100] = processor.tokenizer.pad_token_id\n",
    "#     label_str = processor.decode(labels, skip_special_tokens=True)\n",
    "#     if label_str == \"\":\n",
    "#         print(f\"Label string at index {i} is empty.\")\n",
    "#         break\n",
    "# else: \n",
    "#     print(\"No errors found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33a269f5-3950-4f2a-aa31-f00d986bed11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQgJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCABGAC8DASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD2Mdjv/M9eKXJYNgkenFGO2OvWggg5z+leTc1DBz0JB6frRkHnH/1qACoA/GkJxnJwo6n0p7gDH5c9wM+1KvUcE85psckc0YdHDg85Bo4yc/dHHIo62GOxkE4BHTA60AHqPyxSHseT+NUtY1W30TR7jUrziCBMvjqcnAA+pIFGrA8k8UeMbvU/Fl1pcmtyaHplrK0XmxxOzOVOCcLyeR6jiqN5rGqaTp1xNp/jAa5aSxNDLHM7CRAykbgrnIxnqK9A8OfELT9f1QaVJps1nNMN0QmAIkwMnt1xz+FN8ZaN4M0+wF5rWmiNZZREJLZCHDEE9vofWulSSai0RbqJ8JoWTwPFKzkmaeR8Ek4wduP0/Wu7wrZAxjpisfw9o9poWiW9jYvNJbJl0MuN4DHPoPWtbq2SM44IrGTvJspLQAcqCGB9Kztd0eHXtFu9LmZkiuFA3L1BBBBH0IFaOfbNct478RXfhzQY5rLyhcXFyturzD5YshiWPbjH60opt6AzgNA06+sfjDY2F9qL372cLhZGPRDE2AM9PvCtv4yyNLZ6NYLybi6ZgPXAC/8As9cfZ61q+hePbnVrpbfWrpIP9Iks2DIqHaNwKjAxgDp3rZ8T+JtO8X+JvCP2AsVjuMyRuuGQs6cH/vnt611NS50/Ii+h7DGpFugUcqoxn6VJgAjpnuTQACAB1xg560nQZAyT1965DQXjoQevf6VS1PTLLWLGSy1G2S4gkOWRjjH4jkY9qufeycDkgUE4zgcZ5yaSdgMjRvC2jeHRMNLsUg80YclixI9MsScfjWQvw60NPEsWu2vnW8kcnmeRGV8otyM7cZHrwfyrr26cD9KU84OOeuKfM11FZWEOQTjrSA7m2g8jg5+lG7aAB396XjJ/r60rpbgIxwgJH3uKcAc5JzzRRU3AYCME/wB3rSlf3gBJz0wD6UUU5NoYrZUnAH1z3poYfdIPHP50UVUNR9D/2Q==",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=47x70>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = Image.open(train_dataset.root_dir + train_df['file_name'][0]).convert(\"RGB\")\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0e11b90-9c88-4bed-ab87-f9913fa10247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "มี\n"
     ]
    }
   ],
   "source": [
    "labels = encoding['labels']\n",
    "labels[labels == -100] = processor.tokenizer.pad_token_id\n",
    "label_str = processor.decode(labels, skip_special_tokens=True)\n",
    "print(label_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cba059-aa70-448d-9ff9-7ad2964aff09",
   "metadata": {},
   "source": [
    "# Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f29646a0-5c38-4fbc-818c-a467eca33e1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import VisionEncoderDecoderModel, GenerationConfig, CamembertForCausalLM, VisionEncoderDecoderConfig\n",
    "\n",
    "# encoder = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-base-handwritten').encoder\n",
    "# encoder.save_pretrained('encoder')\n",
    "\n",
    "# model = VisionEncoderDecoderModel.from_encoder_decoder_pretrained(\"encoder\", \"airesearch/wangchanberta-base-att-spm-uncased\")\n",
    "# model.config\n",
    "# model = VisionEncoderDecoderModel.from_pretrained('kkatiz/thai-trocr-thaigov-v2')\n",
    "model = VisionEncoderDecoderModel.from_pretrained('nithan-ocr/checkpoint-500/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21a346c1-03cb-48e7-8601-b42b30dce12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set special tokens used for creating the decoder_input_ids from the labels\n",
    "model.config.decoder_start_token_id = processor.tokenizer.cls_token_id\n",
    "model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
    "# make sure vocab size is set correctly\n",
    "model.config.vocab_size = model.config.decoder.vocab_size\n",
    "\n",
    "# # set beam search parameters\n",
    "# model.config.eos_token_id = processor.tokenizer.sep_token_id\n",
    "# model.config.max_length = 64\n",
    "# model.config.early_stopping = True\n",
    "# model.config.no_repeat_ngram_size = 3\n",
    "# model.config.length_penalty = 2.0\n",
    "# model.config.num_beams = 4\n",
    "\n",
    "model.generation_config = GenerationConfig(\n",
    "    decoder_start_token_id = processor.tokenizer.cls_token_id,\n",
    "    pad_token_id = processor.tokenizer.pad_token_id,\n",
    "    vocab_size = model.config.decoder.vocab_size,\n",
    "    max_length = 64,\n",
    "    eos_token_id = processor.tokenizer.sep_token_id,\n",
    "    early_stopping = True,\n",
    "    no_repeat_ngram_size = 3,\n",
    "    length_penalty = 2.0,\n",
    "    num_beams = 4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11ce6833-f2dc-441d-b321-803452ef6c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:u1054yoa) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Ensure read and write access to run files dir: /home/wandb/run-20240308_232845-u1054yoa/files, control this via the WANDB_DIR env var. See https://docs.wandb.ai/guides/track/environment-variables\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/cer</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/grad_norm</td><td>▂▂▁▁▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂█▁▁▁▁▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/loss</td><td>▆█▆▄▅▆▅▅▆▅▅▄▄▄▄▄▄▃▂▂▃▂▄▅▄▄▂▂▂▃▃▃▄▃▃▁▃▄▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/cer</td><td>0.10547</td></tr><tr><td>eval/loss</td><td>0.27436</td></tr><tr><td>eval/runtime</td><td>192.3404</td></tr><tr><td>eval/samples_per_second</td><td>25.996</td></tr><tr><td>eval/steps_per_second</td><td>0.816</td></tr><tr><td>train/epoch</td><td>0.45</td></tr><tr><td>train/global_step</td><td>636</td></tr><tr><td>train/grad_norm</td><td>347936.71875</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>0.3295</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">nithan-ocr</strong> at: <a href='https://wandb.ai/kkatiz/thai-ocr/runs/u1054yoa' target=\"_blank\">https://wandb.ai/kkatiz/thai-ocr/runs/u1054yoa</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240308_232845-u1054yoa/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:u1054yoa). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ce2f7e9bcfa4699aa55134cd7940d15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112987433767154, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/wandb/run-20240308_234808-u1054yoa</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/kkatiz/thai-ocr/runs/u1054yoa' target=\"_blank\">nithan-ocr</a></strong> to <a href='https://wandb.ai/kkatiz/thai-ocr' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kkatiz/thai-ocr' target=\"_blank\">https://wandb.ai/kkatiz/thai-ocr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kkatiz/thai-ocr/runs/u1054yoa' target=\"_blank\">https://wandb.ai/kkatiz/thai-ocr/runs/u1054yoa</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "import wandb\n",
    "\n",
    "model_name = 'nithan-ocr'\n",
    "\n",
    "wandb.init(project=\"thai-ocr\", name=model_name, resume=True)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    predict_with_generate=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    fp16=True, \n",
    "    output_dir=model_name,\n",
    "    weight_decay=0.01,\n",
    "    learning_rate=2e-5,\n",
    "    logging_steps=2,\n",
    "    save_steps=500,\n",
    "    eval_steps=500,\n",
    "    warmup_steps=843, # ((len(dataset) / batch_size) * n_epochs) * want_protion e.g 0.1\n",
    "    num_train_epochs = 3,\n",
    "    overwrite_output_dir=True,\n",
    "    save_total_limit=3,\n",
    "    report_to='wandb',\n",
    "    run_name=model_name,\n",
    "    resume_from_checkpoint=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "730ff0c7-e597-4ea7-b232-0721478524d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "cer_metric = evaluate.load(\"cer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5fd37b9-0372-42ed-a219-2fc703c8282a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    labels_ids[labels_ids == -100] = processor.tokenizer.pad_token_id\n",
    "    label_str = processor.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "\n",
    "    cer = cer_metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"cer\": cer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9766fd25-8f5b-4975-8868-d14c5c84f2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "There were missing keys in the checkpoint model loaded: ['decoder.lm_head.decoder.weight', 'decoder.lm_head.decoder.bias'].\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3750' max='3750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3750/3750 1:44:39, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Cer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.172000</td>\n",
       "      <td>0.164313</td>\n",
       "      <td>0.065633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.061600</td>\n",
       "      <td>0.119879</td>\n",
       "      <td>0.044115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.053300</td>\n",
       "      <td>0.090604</td>\n",
       "      <td>0.033867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.036900</td>\n",
       "      <td>0.070106</td>\n",
       "      <td>0.027196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>0.063369</td>\n",
       "      <td>0.022938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.037600</td>\n",
       "      <td>0.058463</td>\n",
       "      <td>0.020354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3750, training_loss=0.08984003741629422, metrics={'train_runtime': 6280.8699, 'train_samples_per_second': 19.106, 'train_steps_per_second': 0.597, 'total_flos': 6.392185002786816e+19, 'train_loss': 0.08984003741629422, 'epoch': 3.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import default_data_collator\n",
    "\n",
    "# instantiate trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    tokenizer=processor.image_processor,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=default_data_collator,\n",
    ")\n",
    "trainer.train(resume_from_checkpoint=True)\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1958b8b5-401c-41ae-b2b8-3b7dd7d0ddef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='313' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [313/313 06:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.05729099363088608,\n",
       " 'eval_cer': 0.019161982626469086,\n",
       " 'eval_runtime': 385.8082,\n",
       " 'eval_samples_per_second': 25.92,\n",
       " 'eval_steps_per_second': 0.811,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "61332cef-3ea4-45f4-aefd-f92ad85b6d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQgJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAA2ADIDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD1FdqDHJGCeQAc/lz1pCMsuThScEkf57Gjg9M7znP0x9fbP4mo7mWK3hNzdSJDCAC8krbVUeuT0rwzq1JifnOO/IwewJ74+tI+S4QAEEfw8cdv896xL3xdoNnBHdHVbaaJ51hDW8okG584Hy9+K2cugZmdicHHPbOB/Wqs1qKwI5IBAymPXpj/ACf8OKcGDIPT7ucdaQqdwA+6c8jmkw29d7KWJ59v/r8VO+o9xxm5Py5/D/61FAR8D9zH+f8A9aii3n/X3k8y7EbIVbHzcgbSTnP+ev4VyHxB0vRb/S4Z/EGrzadbWshKKhVlkc4xlCrbsY6Y/iNdiiH7rdl+mR39qxPEXhjTvEtrDHqfnL5BLwyxSlGjfgbs5wfrWkHaV2U1dHj9poeh6h4n0htL8RadcKt7E7W5ga3aUBgcbQoXOM46da9xttU028upLe0vrOaWPIljjnDtH25UdPxrzzwYkNn8QL3RY7611m2hsvtEd4yK80T71UoZF5PX19KqeDPD0OgfFq901ZzcRW2mFk/dqhyzrgNtHznDHk8/lW9RKe/RGauj1vCncuQSBnAHTimYbPAz29Me1cE+y/8Ajpud2BsNGH4Oz9Pyeu/bqVJIJ5BIPfHf1/xrlcbW8zRXYza5/gi/JqKmWAbRu645+c0VN/MNBrSYUnkAcZA4H+f61UvbYXdjc2sjOgmhZGZCMpuB5Hvg/wCc1bCYO4ckZwPTn9P8+lN3Bk2ghepA9B9KpabCVji/Bfw+XwjqVzeyXq3ck0awqUtlhCoCOoBIJ45NVtT0HxHpnjS88R+HLe1vlvoUjmtLltjJtAA2nPIOO/rXeFSZVCvlcc+hHH6/40qZZVwgAYDnAyPpjt/hV+0lfmYrKxxPhDQdZj8R6v4k16OG3vr9UjjtoG3+Wi4HUcdl/wDrV2ysVyRhseuRj2pGGIlU/dLHjPfrTiV34+8vTGDgjB6fypSlzajtYcEYjPmyf8BDY/CikVY9ozI+cdnYfyOKKnmY9SAybGV2VSWBOev+eKlLeU205JHJOeo+lFFJpWKsiQKXds4J44/KocZyGAJ3bemOckf5NFFJEXDzA6AsCR0x+Gf8KXIY4GSu3PPvjP06iiircV/XqP7ViNp1VypgU4OM7v8A61FFFdns4m3s4n//2Q==",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=50x54>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "รีบ\n"
     ]
    }
   ],
   "source": [
    "image = Image.open('single_result/images/0/139.jpg').convert(\"RGB\")\n",
    "pixel_values = processor(image, return_tensors=\"pt\").pixel_values.to('cuda')\n",
    "generated_ids = model.generate(pixel_values)\n",
    "\n",
    "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "display(image)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0234ae5-a9f0-4f31-b00d-62e9099f4535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.save_pretrained('best_model')\n",
    "# processor.save_pretrained('best_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "75fa3491-4f13-4bcd-b854-f32f9e6ad929",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test_model = VisionEncoderDecoderModel.from_pretrained('best_model')\n",
    "# test_processor = TrOCRProcessor.from_pretrained('best_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d10b8d89-7160-49af-92fb-1105a48d658a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b33f36e04d79437d893117c0795ae762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/881M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9844719a11ef489ba81c24bf016ceb32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f13a78748b9475e9f691366c6f8411c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/905k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/kkatiz/ocr-nithan/commit/b55c31aebf69b5acb51eb92b1381a2dc83cf7df2', commit_message='Upload processor', commit_description='', oid='b55c31aebf69b5acb51eb92b1381a2dc83cf7df2', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.push_to_hub(\"ocr-nithan\", private=True)\n",
    "# processor.push_to_hub('ocr-nithan', private=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
